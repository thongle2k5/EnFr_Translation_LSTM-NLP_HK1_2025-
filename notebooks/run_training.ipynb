{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea4da445",
   "metadata": {},
   "source": [
    "# 1 Th√™m th∆∞ vi·ªán c·∫ßn thi·∫øt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ced4b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from src.train import train_epoch, evaluate, epoch_time\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import itertools\n",
    "import sys\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab6d947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ ƒêang s·ª≠ d·ª•ng thi·∫øt b·ªã: cpu\n",
      "‚è≥ ƒêang t·∫£i d·ªØ li·ªáu...\n",
      "‚è≥ Building Vocab...\n",
      "‚úÖ ƒê√£ kh·ªüi t·∫°o xong Data v√† Model. S·∫µn s√†ng c·∫•u h√¨nh hu·∫•n luy·ªán!\n"
     ]
    }
   ],
   "source": [
    "# --- CH√àN ƒêO·∫†N N√ÄY V√ÄO GI·ªÆA CELL IMPORT V√Ä CELL C·∫§U H√åNH ---\n",
    "\n",
    "# Th√™m ƒë∆∞·ªùng d·∫´n ƒë·ªÉ import ƒë∆∞·ª£c code t·ª´ th∆∞ m·ª•c src\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from src.dataset import get_loaders\n",
    "from src.model import Encoder, Decoder, Seq2Seq\n",
    "\n",
    "# 1. C·∫•u h√¨nh thi·∫øt b·ªã\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üîπ ƒêang s·ª≠ d·ª•ng thi·∫øt b·ªã: {device}\")\n",
    "\n",
    "# 2. Load D·ªØ li·ªáu (ƒê·ªÉ c√≥ train_loader, vocab_en, vocab_fr)\n",
    "BATCH_SIZE = 64\n",
    "path_en = '../data/raw/train.en'\n",
    "path_fr = '../data/raw/train.fr'\n",
    "\n",
    "print(\"‚è≥ ƒêang t·∫£i d·ªØ li·ªáu...\")\n",
    "full_train_loader, vocab_en, vocab_fr = get_loaders(BATCH_SIZE, path_en, path_fr)\n",
    "#train_loader = list(itertools.islice(full_train_loader, 5))\n",
    "train_loader=full_train_loader\n",
    "# 3. Kh·ªüi t·∫°o M√¥ h√¨nh (ƒê·ªÉ c√≥ bi·∫øn model)\n",
    "INPUT_DIM = len(vocab_en)\n",
    "OUTPUT_DIM = len(vocab_fr)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DROPOUT)\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "# Kh·ªüi t·∫°o tr·ªçng s·ªë (gi√∫p model h·ªçc nhanh h∆°n)\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            torch.nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            torch.nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)\n",
    "\n",
    "print(\"‚úÖ ƒê√£ kh·ªüi t·∫°o xong Data v√† Model. S·∫µn s√†ng c·∫•u h√¨nh hu·∫•n luy·ªán!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7b82cf",
   "metadata": {},
   "source": [
    "# 2 C·∫•u h√¨nh hu·∫•n luy·ªán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1f4cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C·∫•u h√¨nh theo g·ª£i √Ω c·ªßa ƒë·ªÅ b√†i\n",
    "LEARNING_RATE = 0.001\n",
    "N_EPOCHS = 10       # Ch·∫°y th·ª≠ 10 v√≤ng\n",
    "CLIP = 1.0          # C·∫Øt gradient n·∫øu l·ªõn h∆°n 1\n",
    "PATIENCE = 3        # Early Stopping: D·ª´ng n·∫øu sau 3 l·∫ßn kh√¥ng ti·∫øn b·ªô\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c l∆∞u model n·∫øu ch∆∞a c√≥\n",
    "import os\n",
    "if not os.path.exists('../checkpoints'):\n",
    "    os.makedirs('../checkpoints')\n",
    "\n",
    "model_save_path = '../checkpoints/best_model.pth'\n",
    "\n",
    "# B·ªè qua vi·ªác t√≠nh loss cho token <pad>\n",
    "PAD_IDX = vocab_fr['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "# D√πng Adam Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42d36fb",
   "metadata": {},
   "source": [
    "# 3 T·∫°o v√≤ng l·∫∑p hu·∫•n luy·ªán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a74520eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán: cpu\n",
      "ƒê√£ l∆∞u model t·ªët h∆°n t·∫°i epoch 1!\n",
      "Epoch: 01 | Time: 0m 15s\n",
      "\tTrain Loss: 9.198 | Train PPL: 9877.793\n",
      "\t Val. Loss: 9.085 |  Val. PPL: 8819.658\n",
      "ƒê√£ l∆∞u model t·ªët h∆°n t·∫°i epoch 2!\n",
      "Epoch: 02 | Time: 0m 15s\n",
      "\tTrain Loss: 7.564 | Train PPL: 1927.334\n",
      "\t Val. Loss: 5.466 |  Val. PPL: 236.575\n",
      "ƒê√£ l∆∞u model t·ªët h∆°n t·∫°i epoch 3!\n",
      "Epoch: 03 | Time: 0m 15s\n",
      "\tTrain Loss: 5.336 | Train PPL: 207.611\n",
      "\t Val. Loss: 5.166 |  Val. PPL: 175.133\n",
      "ƒê√£ l∆∞u model t·ªët h∆°n t·∫°i epoch 4!\n",
      "Epoch: 04 | Time: 0m 15s\n",
      "\tTrain Loss: 5.137 | Train PPL: 170.254\n",
      "\t Val. Loss: 5.027 |  Val. PPL: 152.404\n",
      "ƒê√£ l∆∞u model t·ªët h∆°n t·∫°i epoch 5!\n",
      "Epoch: 05 | Time: 0m 15s\n",
      "\tTrain Loss: 5.014 | Train PPL: 150.501\n",
      "\t Val. Loss: 4.928 |  Val. PPL: 138.085\n",
      "ƒê√£ l∆∞u model t·ªët h∆°n t·∫°i epoch 6!\n",
      "Epoch: 06 | Time: 0m 15s\n",
      "\tTrain Loss: 4.918 | Train PPL: 136.722\n",
      "\t Val. Loss: 4.848 |  Val. PPL: 127.433\n",
      "ƒê√£ l∆∞u model t·ªët h∆°n t·∫°i epoch 7!\n",
      "Epoch: 07 | Time: 0m 16s\n",
      "\tTrain Loss: 4.845 | Train PPL: 127.115\n",
      "\t Val. Loss: 4.787 |  Val. PPL: 119.950\n",
      "ƒê√£ l∆∞u model t·ªët h∆°n t·∫°i epoch 8!\n",
      "Epoch: 08 | Time: 0m 15s\n",
      "\tTrain Loss: 4.789 | Train PPL: 120.213\n",
      "\t Val. Loss: 4.739 |  Val. PPL: 114.367\n",
      "ƒê√£ l∆∞u model t·ªët h∆°n t·∫°i epoch 9!\n",
      "Epoch: 09 | Time: 0m 14s\n",
      "\tTrain Loss: 4.743 | Train PPL: 114.811\n",
      "\t Val. Loss: 4.702 |  Val. PPL: 110.211\n",
      "ƒê√£ l∆∞u model t·ªët h∆°n t·∫°i epoch 10!\n",
      "Epoch: 10 | Time: 0m 15s\n",
      "\tTrain Loss: 4.709 | Train PPL: 110.970\n",
      "\t Val. Loss: 4.672 |  Val. PPL: 106.936\n"
     ]
    }
   ],
   "source": [
    "print(f\"B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán: {device}\")\n",
    "best_valid_loss = float('inf')\n",
    "no_improve_count = 0  # ƒê·∫øm s·ªë l·∫ßn kh√¥ng ti·∫øn b·ªô\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 1. Train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, CLIP, device)\n",
    "    \n",
    "    # 2. Evaluate (D√πng t·∫≠p train t·∫°m n·∫øu ch∆∞a c√≥ val_loader, nh∆∞ng ƒë√∫ng ra ph·∫£i d√πng val_loader)\n",
    "    # L∆∞u √Ω: B·∫°n c·∫ßn t·∫°o th√™m val_loader t∆∞∆°ng t·ª± train_loader ·ªü b∆∞·ªõc tr∆∞·ªõc\n",
    "    valid_loss = evaluate(model, train_loader, criterion, device) \n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    # L∆∞u l·∫°i l·ªãch s·ª≠ ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    # --- EARLY STOPPING & CHECKPOINT ---\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), model_save_path) # L∆∞u model t·ªët nh·∫•t\n",
    "        print(f\"ƒê√£ l∆∞u model t·ªët h∆°n t·∫°i epoch {epoch+1}!\")\n",
    "        no_improve_count = 0\n",
    "    else:\n",
    "        no_improve_count += 1\n",
    "        print(f\"Loss kh√¥ng gi·∫£m ({no_improve_count}/{PATIENCE})\")\n",
    "        \n",
    "    if no_improve_count >= PATIENCE:\n",
    "        print(\"D·ª´ng s·ªõm (Early Stopping) v√¨ model kh√¥ng c√≤n h·ªçc t·ªët h∆°n n·ªØa.\")\n",
    "        break\n",
    "        \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faceai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
