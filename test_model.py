import torch
from src.dataset import create_dataset_and_loaders
from src.model import Encoder, Decoder, Seq2Seq

# Cáº¥u hÃ¬nh giáº£ láº­p
INPUT_DIM = 1000  # Giáº£ sá»­ tá»« Ä‘iá»ƒn Anh cÃ³ 1000 tá»«
OUTPUT_DIM = 1000 # Giáº£ sá»­ tá»« Ä‘iá»ƒn PhÃ¡p cÃ³ 1000 tá»«
ENC_EMB_DIM = 32
DEC_EMB_DIM = 32
HID_DIM = 64
N_LAYERS = 2
ENC_DROPOUT = 0.5
DEC_DROPOUT = 0.5

# Thiáº¿t bá»‹ (GPU hoáº·c CPU)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

if __name__ == "__main__":
    print(f"âš™ï¸ Äang kiá»ƒm tra Model trÃªn thiáº¿t bá»‹: {device}")
    
    # 1. Khá»Ÿi táº¡o cÃ¡c khá»‘i
    enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)
    dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)
    model = Seq2Seq(enc, dec, device).to(device)
    
    print("âœ… Khá»Ÿi táº¡o Model thÃ nh cÃ´ng!")
    
    # 2. Táº¡o dá»¯ liá»‡u giáº£ Ä‘á»ƒ test
    # Batch size = 4, CÃ¢u dÃ i 10 tá»«
    src = torch.randint(0, INPUT_DIM, (10, 4)).to(device) # [src_len, batch_size]
    trg = torch.randint(0, OUTPUT_DIM, (12, 4)).to(device) # [trg_len, batch_size]
    
    print(f" - Shape Input (Anh): {src.shape}")
    print(f" - Shape Target (PhÃ¡p): {trg.shape}")
    
    # 3. Cháº¡y thá»­ (Forward pass)
    output = model(src, trg)
    
    print(f" - Shape Output (Dá»± Ä‘oÃ¡n): {output.shape}")
    
    # Kiá»ƒm tra shape output
    # Output chuáº©n pháº£i lÃ : [trg_len, batch_size, output_dim]
    expected_shape = (12, 4, 1000)
    
    if output.shape == expected_shape:
        print("\nğŸ‰ CHÃšC Má»ªNG! Model hoáº¡t Ä‘á»™ng chuáº©n shape. Sáºµn sÃ ng Ä‘á»ƒ train!")
    else:
        print(f"\nâŒ Sai shape rá»“i! Mong Ä‘á»£i {expected_shape}, nhÆ°ng nháº­n Ä‘Æ°á»£c {output.shape}")